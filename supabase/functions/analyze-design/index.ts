import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

console.log('üöÄ Streamlined Analysis Function - Starting up');

// Helper function to convert coordinates to spatial context
function getSpatialContext(x, y) {
  const xPos = x < 33 ? 'left' : x > 66 ? 'right' : 'center';
  const yPos = y < 33 ? 'top' : y > 66 ? 'bottom' : 'middle';
  
  if (xPos === 'center' && yPos === 'middle') return 'center of screen';
  if (xPos === 'left' && yPos === 'top') return 'top-left corner';
  if (xPos === 'right' && yPos === 'top') return 'top-right corner';
  if (xPos === 'left' && yPos === 'bottom') return 'bottom-left corner';
  if (xPos === 'right' && yPos === 'bottom') return 'bottom-right corner';
  
  return `${yPos} ${xPos} area`;
}

// Google Vision Analysis Function
async function analyzeWithGoogleVision(imageUrl) {
  const analysisId = crypto.randomUUID().substring(0, 8);
  console.log(`üîç [${analysisId}] Starting Google Vision analysis for:`, imageUrl.substring(0, 100) + '...');
  
  try {
    // Step 1: Get Google Cloud credentials
    const googleCredentials = Deno.env.get('GOOGLE_CLOUD_CREDENTIALS');
    if (!googleCredentials) {
      throw new Error('Google Cloud credentials not configured');
    }

    let credentials;
    try {
      credentials = JSON.parse(googleCredentials);
    } catch (parseError) {
      throw new Error('Invalid Google Cloud credentials format');
    }

    // Step 2: Convert image to base64
    console.log(`üîÑ [${analysisId}] Converting image to base64...`);
    const imageResponse = await fetch(imageUrl);
    if (!imageResponse.ok) {
      throw new Error(`Failed to fetch image: ${imageResponse.status}`);
    }
    
    const arrayBuffer = await imageResponse.arrayBuffer();
    const uint8Array = new Uint8Array(arrayBuffer);
    let binaryString = '';
    
    // Process in small chunks to avoid stack overflow
    const chunkSize = 1024; // Reduced chunk size
    for (let i = 0; i < uint8Array.length; i += chunkSize) {
      const chunk = uint8Array.slice(i, i + chunkSize);
      // Use loop instead of spread operator to avoid stack overflow
      for (let j = 0; j < chunk.length; j++) {
        binaryString += String.fromCharCode(chunk[j]);
      }
    }
    
    const base64Data = btoa(binaryString);
    console.log(`‚úÖ [${analysisId}] Image converted to base64, size: ${base64Data.length} chars`);

    // Step 3: Get access token
    console.log(`üîë [${analysisId}] Getting access token...`);
    const accessToken = await getAccessToken(credentials, analysisId);
    
    // Step 4: Call Google Vision API
    console.log(`üöÄ [${analysisId}] Calling Google Vision API...`);
    const visionResponse = await fetch('https://vision.googleapis.com/v1/images:annotate', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${accessToken}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        requests: [{
          image: { content: base64Data },
          features: [
            { type: 'TEXT_DETECTION' },
            { type: 'OBJECT_LOCALIZATION', maxResults: 20 },
            { type: 'IMAGE_PROPERTIES' },
            { type: 'LABEL_DETECTION', maxResults: 20 }
          ]
        }]
      })
    });

    if (!visionResponse.ok) {
      const errorText = await visionResponse.text();
      throw new Error(`Google Vision API error: ${visionResponse.status} - ${errorText}`);
    }

    const visionData = await visionResponse.json();
    const firstResponse = visionData.responses[0];
    
    if (firstResponse?.error) {
      throw new Error(`Google Vision API error: ${firstResponse.error.message}`);
    }

    // Step 5: Process and return structured data
    return processGoogleVisionResponse(firstResponse, analysisId);
    
  } catch (error) {
    console.error(`‚ùå [${analysisId}] Google Vision analysis failed:`, error.message);
    throw error;
  }
}

// Access token generation
async function getAccessToken(credentials, analysisId) {
  const jwtHeader = { alg: 'RS256', typ: 'JWT' };
  const now = Math.floor(Date.now() / 1000);
  const jwtPayload = {
    iss: credentials.client_email,
    scope: 'https://www.googleapis.com/auth/cloud-vision',
    aud: 'https://oauth2.googleapis.com/token',
    exp: now + 3600,
    iat: now
  };

  const encodedHeader = btoa(JSON.stringify(jwtHeader)).replace(/=/g, '').replace(/\+/g, '-').replace(/\//g, '_');
  const encodedPayload = btoa(JSON.stringify(jwtPayload)).replace(/=/g, '').replace(/\+/g, '-').replace(/\//g, '_');
  const unsignedToken = `${encodedHeader}.${encodedPayload}`;

  const privateKeyFormatted = credentials.private_key
    .replace(/-----BEGIN PRIVATE KEY-----/, '')
    .replace(/-----END PRIVATE KEY-----/, '')
    .replace(/\n/g, '');

  const privateKeyBuffer = Uint8Array.from(atob(privateKeyFormatted), c => c.charCodeAt(0));
  const cryptoKey = await crypto.subtle.importKey(
    'pkcs8', privateKeyBuffer,
    { name: 'RSASSA-PKCS1-v1_5', hash: 'SHA-256' },
    false, ['sign']
  );

  const signature = await crypto.subtle.sign(
    'RSASSA-PKCS1-v1_5', cryptoKey,
    new TextEncoder().encode(unsignedToken)
  );

  const encodedSignature = btoa(String.fromCharCode(...new Uint8Array(signature)))
    .replace(/=/g, '').replace(/\+/g, '-').replace(/\//g, '_');

  const signedJWT = `${unsignedToken}.${encodedSignature}`;

  const tokenResponse = await fetch('https://oauth2.googleapis.com/token', {
    method: 'POST',
    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
    body: new URLSearchParams({
      grant_type: 'urn:ietf:params:oauth:grant-type:jwt-bearer',
      assertion: signedJWT
    })
  });

  if (!tokenResponse.ok) {
    const errorText = await tokenResponse.text();
    throw new Error(`Token exchange failed: ${tokenResponse.status} - ${errorText}`);
  }

  const tokenData = await tokenResponse.json();
  return tokenData.access_token;
}

// Process Google Vision response
function processGoogleVisionResponse(visionData, analysisId) {
  console.log(`üîÑ [${analysisId}] Processing Google Vision response...`);
  
  const uiElements = [];
  const textContent = [];
  
  // Process object localization
  if (visionData.localizedObjectAnnotations) {
    visionData.localizedObjectAnnotations.forEach((obj) => {
      uiElements.push({
        type: obj.name.toLowerCase(),
        confidence: obj.score || 0.8,
        description: `${obj.name} detected with ${Math.round((obj.score || 0.8) * 100)}% confidence`
      });
    });
  }

  // Process text detection
  if (visionData.textAnnotations) {
    visionData.textAnnotations.forEach((text, index) => {
      if (index === 0) return; // Skip full text annotation
      textContent.push({
        text: text.description || '',
        confidence: 0.9,
        context: 'detected_text'
      });
    });
  }

  // Process image properties for colors
  let dominantColors = ['#ffffff', '#000000', '#0066cc'];
  if (visionData.imagePropertiesAnnotation?.dominantColors?.colors) {
    dominantColors = visionData.imagePropertiesAnnotation.dominantColors.colors
      .slice(0, 3)
      .map((color) => {
        const r = Math.round(color.color.red || 0);
        const g = Math.round(color.color.green || 0);
        const b = Math.round(color.color.blue || 0);
        return `#${r.toString(16).padStart(2, '0')}${g.toString(16).padStart(2, '0')}${b.toString(16).padStart(2, '0')}`;
      });
  }

  const result = {
    uiElements,
    layout: { type: 'web_application', confidence: 0.8, description: 'Web application layout detected' },
    industry: { industry: 'technology', confidence: 0.7, indicators: ['digital interface', 'web elements'] },
    accessibility: [],
    textContent,
    colors: {
      dominantColors,
      colorPalette: {
        primary: dominantColors[0] || '#0066cc',
        secondary: dominantColors[1] || '#666666',
        accent: dominantColors[2] || '#ff6600'
      },
      colorContrast: { textBackground: 4.5, accessibility: 'AA' }
    },
    deviceType: { type: 'desktop', confidence: 0.8, dimensions: { width: 1200, height: 800, aspectRatio: 1.5 } },
    overallConfidence: Math.min(0.9, (uiElements.length * 0.1 + textContent.length * 0.05 + 0.6)),
    processingTime: Date.now()
  };

  console.log(`‚úÖ [${analysisId}] Vision response processed:`, {
    uiElementsFound: result.uiElements.length,
    textContentFound: result.textContent.length,
    colorsFound: result.colors.dominantColors.length,
    confidence: result.overallConfidence
  });

  return result;
}

serve(async (req) => {
  const requestId = crypto.randomUUID().substring(0, 8);
  console.log(`üì® [${requestId}] Request received:`, {
    method: req.method,
    url: req.url,
    timestamp: new Date().toISOString()
  });

  try {
    // Handle CORS
    if (req.method === 'OPTIONS') {
      console.log(`üîç [${requestId}] CORS preflight request`);
      return new Response(null, { headers: corsHeaders });
    }

    if (req.method !== 'POST') {
      console.log(`‚ùå [${requestId}] Invalid method: ${req.method}`);
      return new Response(JSON.stringify({ error: 'Method not allowed' }), {
        status: 405,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      });
    }

    // Parse request body with error handling
    let requestData;
    try {
      const rawBody = await req.text();
      console.log(`üìù [${requestId}] Raw request body length: ${rawBody.length}`);
      
      if (rawBody.length > 1024 * 1024) { // 1MB limit
        throw new Error('Request payload too large (max 1MB)');
      }
      
      requestData = JSON.parse(rawBody);
    } catch (parseError) {
      console.error(`‚ùå [${requestId}] Failed to parse request body:`, parseError);
      return new Response(JSON.stringify({ 
        error: 'Invalid JSON in request body',
        details: parseError.message 
      }), {
        status: 400,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      });
    }

    console.log(`üìä [${requestId}] Request data parsed:`, {
      hasImageUrls: !!requestData.imageUrls,
      imageCount: requestData.imageUrls?.length || 0,
      hasAnalysisPrompt: !!requestData.analysisPrompt,
      promptLength: requestData.analysisPrompt?.length || 0,
      analysisId: requestData.analysisId,
      enableGoogleVision: requestData.enableGoogleVision,
      skipClaudeAnalysis: requestData.skipClaudeAnalysis,
      ragEnabled: requestData.ragEnabled,
      userCommentsCount: requestData.userComments?.length || 0,
      keys: Object.keys(requestData)
    });
    
    // Basic validation
    if (!requestData.imageUrls || requestData.imageUrls.length === 0) {
      // Try to fetch from database if analysisId is provided
      if (requestData.analysisId) {
        console.log('üîç Fetching images from database for analysis:', requestData.analysisId);
        
        const supabaseUrl = Deno.env.get('SUPABASE_URL');
        const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY');
        
        if (supabaseUrl && supabaseServiceKey) {
          const { createClient } = await import('https://esm.sh/@supabase/supabase-js@2.50.0');
          const supabase = createClient(supabaseUrl, supabaseServiceKey);
          
          const { data: uploadedFiles, error } = await supabase
            .from('uploaded_files')
            .select('public_url')
            .eq('analysis_id', requestData.analysisId);

          if (!error && uploadedFiles?.length > 0) {
            requestData.imageUrls = uploadedFiles.map(file => file.public_url).filter(Boolean);
            console.log(`‚úÖ Retrieved ${requestData.imageUrls.length} images from database`);
          }
        }
      }
      
      if (!requestData.imageUrls || requestData.imageUrls.length === 0) {
        return new Response(JSON.stringify({
          success: false,
          error: 'No images provided for analysis'
        }), {
          status: 400,
          headers: { ...corsHeaders, 'Content-Type': 'application/json' }
        });
      }
    }

    // Defensive measure: Provide fallback prompt if missing
    if (!requestData.analysisPrompt || requestData.analysisPrompt.trim() === '') {
      console.log('‚ö†Ô∏è No analysis prompt provided, using fallback');
      requestData.analysisPrompt = `Comprehensive UX analysis of ${requestData.imageUrls?.length || 1} design image(s). Provide detailed feedback on usability, visual hierarchy, accessibility, and user experience improvements.`;
    }

    // If this is a Google Vision-only request, skip Claude analysis
    if (requestData.enableGoogleVision && requestData.skipClaudeAnalysis) {
      console.log('üëÅÔ∏è Google Vision only analysis requested...');
      
      let googleVisionData = null;
      try {
        const visionStartTime = Date.now();
        googleVisionData = await analyzeWithGoogleVision(requestData.imageUrls[0]);
        const visionTime = Date.now() - visionStartTime;
        console.log(`‚úÖ Google Vision analysis completed in ${visionTime}ms`);
        
        return new Response(JSON.stringify({
          success: true,
          googleVisionData,
          imageCount: requestData.imageUrls.length,
          analysisId: requestData.analysisId,
          processingTime: visionTime
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' }
        });
        
      } catch (visionError) {
        console.error('‚ùå Google Vision analysis failed:', visionError.message);
        return new Response(JSON.stringify({
          success: false,
          error: 'Google Vision analysis failed',
          details: visionError.message
        }), {
          status: 500,
          headers: { ...corsHeaders, 'Content-Type': 'application/json' }
        });
      }
    }

    // Call Claude Sonnet 4 for analysis
    const claudeApiKey = Deno.env.get('ANTHROPIC_API_KEY');
    if (!claudeApiKey) {
      return new Response(JSON.stringify({
        success: false,
        error: 'Claude API key not configured'
      }), {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      });
    }

    console.log('ü§ñ Starting AI analysis with Claude Sonnet 4...');

    // Step 1: Get Google Vision data for enhanced context
    console.log('üëÅÔ∏è Starting Google Vision analysis...');
    let googleVisionData = null;
    
    try {
      const visionStartTime = Date.now();
      googleVisionData = await analyzeWithGoogleVision(requestData.imageUrls[0]); // Analyze first image
      const visionTime = Date.now() - visionStartTime;
      console.log(`‚úÖ Google Vision analysis completed in ${visionTime}ms:`, {
        uiElementsFound: googleVisionData?.uiElements?.length || 0,
        textContentFound: googleVisionData?.textContent?.length || 0,
        colorsFound: googleVisionData?.colors?.dominantColors?.length || 0,
        confidence: googleVisionData?.overallConfidence || 0
      });
    } catch (visionError) {
      console.warn('‚ö†Ô∏è Google Vision analysis failed, continuing without vision data:', visionError.message);
      googleVisionData = null;
    }

    // Step 2: Prepare images for Claude
    console.log('üîç Processing images for Claude:', requestData.imageUrls);
    const imageContent = [];
    for (const imageUrl of requestData.imageUrls) {
      try {
        console.log('üì• Fetching image:', imageUrl);
        const response = await fetch(imageUrl);
        console.log('üì° Image fetch response:', response.status, response.statusText);
        
        if (!response.ok) {
          console.error('‚ùå Failed to fetch image:', imageUrl, 'Status:', response.status, response.statusText);
          continue;
        }
        
        const imageData = await response.arrayBuffer();
        console.log('üìä Image data size:', imageData.byteLength, 'bytes');
        
        if (imageData.byteLength === 0) {
          console.error('‚ùå Image data is empty for:', imageUrl);
          continue;
        }
        
        // Convert to base64 safely to avoid stack overflow
        const uint8Array = new Uint8Array(imageData);
        let binaryString = '';
        const chunkSize = 1024;
        for (let i = 0; i < uint8Array.length; i += chunkSize) {
          const chunk = uint8Array.slice(i, i + chunkSize);
          for (let j = 0; j < chunk.length; j++) {
            binaryString += String.fromCharCode(chunk[j]);
          }
        }
        const base64 = btoa(binaryString);
        console.log('‚úÖ Image converted to base64, length:', base64.length);
        
        imageContent.push({
          type: "image",
          source: {
            type: "base64",
            media_type: "image/png",
            data: base64
          }
        });
      } catch (error) {
        console.error('‚ùå Error processing image:', imageUrl, error.message);
      }
    }

    if (imageContent.length === 0) {
      return new Response(JSON.stringify({
        success: false,
        error: 'No valid images could be processed'
      }), {
        status: 400,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      });
    }

    // Step 3: Build enhanced context with image-specific annotations
    console.log('üß† Building enhanced analysis context...');
    let enhancedPrompt = requestData.analysisPrompt;
    
    // Process user comments with coordinate-aware context
    if (requestData.userComments && requestData.userComments.length > 0) {
      console.log('üìù Processing', requestData.userComments.length, 'user annotations...');
      
      // Group comments by image if multiple images
      const commentsByImage = {};
      requestData.userComments.forEach((comment, index) => {
        const imageKey = comment.imageUrl || comment.imageIndex || 0;
        if (!commentsByImage[imageKey]) {
          commentsByImage[imageKey] = [];
        }
        commentsByImage[imageKey].push({
          ...comment,
          spatialContext: getSpatialContext(comment.x, comment.y)
        });
      });
      
      // Build image-specific context sections
      let imageContextSections = [];
      Object.keys(commentsByImage).forEach((imageKey, index) => {
        const imageComments = commentsByImage[imageKey];
        const imageContext = `
Image ${index + 1} Specific Feedback:
${imageComments.map((comment, idx) => 
  `‚Ä¢ ${comment.spatialContext}: "${comment.comment}"`
).join('\n')}`;
        imageContextSections.push(imageContext);
      });
      
      // Combine main prompt with image-specific context
      enhancedPrompt = `${requestData.analysisPrompt}

User has provided specific feedback points for the following areas:
${imageContextSections.join('\n\n')}

Please analyze these images with special attention to the user's specific feedback points and provide detailed recommendations that address their concerns.`;
    }

    // Call Claude API with timeout handling
    console.log('ü§ñ Calling Claude API with', imageContent.length, 'images and enhanced context');
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 90000); // 90 second timeout
    
    const claudeResponse = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': claudeApiKey,
        'anthropic-version': '2023-06-01'
      },
      signal: controller.signal,
      body: JSON.stringify({
        model: 'claude-sonnet-4-20250514', // Use faster Sonnet instead of Opus
        max_tokens: 3000, // Reduced for faster response
        messages: [{
          role: 'user',
          content: [
            {
              type: "text",
              text: `As a UX expert, analyze these ${imageContent.length} design images and provide detailed feedback. 

Context: ${enhancedPrompt}

Please provide 12-15 specific, actionable insights in this exact JSON format:
{
  "annotations": [
    {
      "id": "unique-id",
      "title": "Brief insight title",
      "feedback": "Detailed explanation and recommendation",
      "severity": "critical|important|medium|low",
      "category": "UX|Visual Design|Accessibility|Content|Performance",
      "priority": "high|medium|low",
      "coordinates": {"x": 100, "y": 100, "width": 50, "height": 30},
      "businessImpact": "How this affects business goals",
      "implementation": "Specific steps to fix this",
      "tags": ["tag1", "tag2"]
    }
  ]
}`
            },
            ...imageContent
          ]
        }]
      })
    });
    
    clearTimeout(timeoutId);

    if (!claudeResponse.ok) {
      const errorText = await claudeResponse.text();
      console.error('Claude API error:', errorText);
      return new Response(JSON.stringify({
        success: false,
        error: 'AI analysis failed'
      }), {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      });
    }

    const claudeData = await claudeResponse.json();
    const analysisText = claudeData.content[0]?.text || '';

    // Parse JSON from Claude response
    let annotations = [];
    try {
      const jsonMatch = analysisText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const parsed = JSON.parse(jsonMatch[0]);
        annotations = parsed.annotations || [];
      }
    } catch (parseError) {
      console.error('Failed to parse Claude response:', parseError);
      // Fallback: create basic annotations
      annotations = [{
        id: "fallback-1",
        title: "Analysis Complete",
        feedback: "AI analysis completed successfully. Please review the design for UX improvements.",
        severity: "medium",
        category: "UX",
        priority: "medium",
        coordinates: {"x": 50, "y": 50, "width": 100, "height": 50},
        businessImpact: "Improved user experience leads to better conversion",
        implementation: "Review the analysis results and implement suggested changes",
        tags: ["analysis", "review"]
      }];
    }

    // Save results to database
    if (requestData.analysisId) {
      try {
        const supabaseUrl = Deno.env.get('SUPABASE_URL');
        const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY');
        
        if (supabaseUrl && supabaseServiceKey) {
          const { createClient } = await import('https://esm.sh/@supabase/supabase-js@2.50.0');
          const supabase = createClient(supabaseUrl, supabaseServiceKey);
          
          // Get user ID from Supabase auth
          const authHeader = req.headers.get('authorization');
          let userId = null;
          
          if (authHeader) {
            try {
              const { data: { user } } = await supabase.auth.getUser(authHeader.replace('Bearer ', ''));
              userId = user?.id;
            } catch (authError) {
              console.error('Auth error:', authError);
            }
          }
          
          await supabase.from('analysis_results').insert({
            analysis_id: requestData.analysisId,
            annotations: annotations,
            images: requestData.imageUrls,
            total_annotations: annotations.length,
            ai_model_used: 'claude-sonnet-4-20250514',
            processing_time_ms: Date.now(),
            user_id: userId,
            google_vision_data: googleVisionData,
            visual_intelligence: googleVisionData ? {
              confidence: googleVisionData.overallConfidence,
              uiElementsDetected: googleVisionData.uiElements.length,
              textContentFound: googleVisionData.textContent.length,
              colorAnalysis: googleVisionData.colors,
              deviceType: googleVisionData.deviceType
            } : null
          });
          
          console.log('‚úÖ Results saved to database');
        }
      } catch (dbError) {
        console.error('Database save error:', dbError);
      }
    }

    const response = {
      success: true,
      annotations,
      imageCount: requestData.imageUrls.length,
      ragEnhanced: true,
      knowledgeSourcesUsed: 1,
      researchCitations: ['Claude Sonnet 4 Analysis'],
      modelUsed: 'claude-sonnet-4-20250514',
      analysisId: requestData.analysisId,
      googleVisionData: googleVisionData,
      visualIntelligence: googleVisionData ? {
        confidence: googleVisionData.overallConfidence,
        uiElementsDetected: googleVisionData.uiElements.length,
        textContentFound: googleVisionData.textContent.length,
        colorsDetected: googleVisionData.colors.dominantColors.length,
        deviceType: googleVisionData.deviceType.type,
        processingTime: googleVisionData.processingTime
      } : null
    };

    console.log('üéâ Analysis completed successfully:', {
      annotationCount: annotations.length,
      imageCount: requestData.imageUrls.length
    });

    return new Response(JSON.stringify(response), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });

  } catch (error) {
    console.error('üí• Unhandled error in analysis function:', error);
    return new Response(JSON.stringify({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error occurred'
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });
  }
});